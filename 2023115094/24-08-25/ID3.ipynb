{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysMs4OoDqG1Y",
        "outputId": "841796f5-343d-4ea9-cb2d-5a65513bbb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree:\n",
            "[Outlook]\n",
            "  Sunny →\n",
            "    Leaf: No\n",
            "  Overcast →\n",
            "    Leaf: Yes\n",
            "  Rain →\n",
            "    [Wind]\n",
            "      Weak →\n",
            "        Leaf: Yes\n",
            "      Strong →\n",
            "        Leaf: No\n",
            "\n",
            "Prediction for test sample: No\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, label=None):\n",
        "        self.feature = feature  # feature to split on\n",
        "        self.label = label      # label if it's a leaf node\n",
        "        self.children = {}      # dict: feature_value -> child_node\n",
        "\n",
        "\n",
        "def entropy(data, target_attr):\n",
        "    values = data[target_attr].value_counts(normalize=True)\n",
        "    return -sum(p * math.log2(p) for p in values)\n",
        "\n",
        "\n",
        "def information_gain(data, feature, target_attr):\n",
        "    total_entropy = entropy(data, target_attr)\n",
        "    values = data[feature].unique()\n",
        "    weighted_entropy = 0\n",
        "\n",
        "    for value in values:\n",
        "        subset = data[data[feature] == value]\n",
        "        weighted_entropy += (len(subset) / len(data)) * entropy(subset, target_attr)\n",
        "\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "\n",
        "def id3(data, features, target_attr):\n",
        "    labels = data[target_attr].unique()\n",
        "\n",
        "    # Case 1: All examples have same label\n",
        "    if len(labels) == 1:\n",
        "        return Node(label=labels[0])\n",
        "\n",
        "    # Case 2: No more features, return majority label\n",
        "    if not features:\n",
        "        majority_label = data[target_attr].mode()[0]\n",
        "        return Node(label=majority_label)\n",
        "\n",
        "    # Select best feature\n",
        "    gains = {feature: information_gain(data, feature, target_attr) for feature in features}\n",
        "    best_feature = max(gains, key=gains.get)\n",
        "\n",
        "    root = Node(feature=best_feature)\n",
        "\n",
        "    for value in data[best_feature].unique():\n",
        "        subset = data[data[best_feature] == value]\n",
        "        if subset.empty:\n",
        "            majority_label = data[target_attr].mode()[0]\n",
        "            child = Node(label=majority_label)\n",
        "        else:\n",
        "            child = id3(subset, [f for f in features if f != best_feature], target_attr)\n",
        "        root.children[value] = child\n",
        "\n",
        "    return root\n",
        "\n",
        "\n",
        "def predict(node, sample):\n",
        "    # Leaf node\n",
        "    if node.label is not None:\n",
        "        return node.label\n",
        "    # Internal node\n",
        "    feature_value = sample.get(node.feature)\n",
        "    child = node.children.get(feature_value)\n",
        "    if child is None:\n",
        "        return None\n",
        "    return predict(child, sample)\n",
        "\n",
        "\n",
        "def print_tree(node, depth=0):\n",
        "    if node.label is not None:\n",
        "        print(\"  \" * depth + f\"Leaf: {node.label}\")\n",
        "    else:\n",
        "        print(\"  \" * depth + f\"[{node.feature}]\")\n",
        "        for value, child in node.children.items():\n",
        "            print(\"  \" * (depth + 1) + f\"{value} →\")\n",
        "            print_tree(child, depth + 2)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    data = pd.DataFrame([\n",
        "        {\"Outlook\": \"Sunny\", \"Temp\": \"Hot\", \"Humidity\": \"High\", \"Wind\": \"Weak\", \"Play\": \"No\"},\n",
        "        {\"Outlook\": \"Sunny\", \"Temp\": \"Hot\", \"Humidity\": \"High\", \"Wind\": \"Strong\", \"Play\": \"No\"},\n",
        "        {\"Outlook\": \"Overcast\", \"Temp\": \"Hot\", \"Humidity\": \"High\", \"Wind\": \"Weak\", \"Play\": \"Yes\"},\n",
        "        {\"Outlook\": \"Rain\", \"Temp\": \"Mild\", \"Humidity\": \"High\", \"Wind\": \"Weak\", \"Play\": \"Yes\"},\n",
        "        {\"Outlook\": \"Rain\", \"Temp\": \"Cool\", \"Humidity\": \"Normal\", \"Wind\": \"Weak\", \"Play\": \"Yes\"},\n",
        "        {\"Outlook\": \"Rain\", \"Temp\": \"Cool\", \"Humidity\": \"Normal\", \"Wind\": \"Strong\", \"Play\": \"No\"},\n",
        "        {\"Outlook\": \"Overcast\", \"Temp\": \"Cool\", \"Humidity\": \"Normal\", \"Wind\": \"Strong\", \"Play\": \"Yes\"},\n",
        "    ])\n",
        "\n",
        "    features = [\"Outlook\", \"Temp\", \"Humidity\", \"Wind\"]\n",
        "    target = \"Play\"\n",
        "\n",
        "    tree = id3(data, features, target)\n",
        "\n",
        "    print(\"Decision Tree:\")\n",
        "    print_tree(tree)\n",
        "\n",
        "    test_sample = {\"Outlook\": \"Rain\", \"Temp\": \"Cool\", \"Humidity\": \"High\", \"Wind\": \"Strong\"}\n",
        "    print(\"\\nPrediction for test sample:\", predict(tree, test_sample))\n"
      ]
    }
  ]
}